{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №7\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch_directml\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №1: \n",
    "Обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша основная задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку первого занятия.\n",
    "\n",
    "Настоятельно рекомендуем написать код \"с нуля\", лишь поглядывая на готовые примеры, а не просто \"скопировать-вставить\". Это поможет вам в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 8')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f'Image label: {_label}')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 92% accuracy.\n",
    "\n",
    "*Комментарий: для этого достаточно линейных слоев и функций активации.*\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model`.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model = MNISTClassifier() # your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model is not None, 'Please, use `model` variable to store your model'\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].reshape(-1, 784)\n",
    "    y = random_batch[1]\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model(x)    \n",
    "except Exception as e:\n",
    "    print('Something is wrong with the model')\n",
    "    raise e\n",
    "    \n",
    "    \n",
    "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
    "\n",
    "print('Everything seems fine!')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройте параметры модели на обучающей выборке. Рекомендуем поработать с различными оптимизаторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser(__doc__)\n",
    "parser.add_argument(\"--image\", type=str, help=\"Image to classify.\")\n",
    "parser.add_argument('--device', type=str, default='dml', help='The device to use for training.')\n",
    "parser.add_argument('--model', type=str, default='squeezenet1_0', help='The model to use.')\n",
    "args = parser.parse_args()\n",
    "print (args)\n",
    "\n",
    "device = torch_directml.device(torch_directml.default_device())\n",
    "\"\"\"\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.281278 [   32/60000]\n",
      "loss: 2.024430 [ 3232/60000]\n",
      "loss: 1.722945 [ 6432/60000]\n",
      "loss: 1.525511 [ 9632/60000]\n",
      "loss: 1.262764 [12832/60000]\n",
      "loss: 0.894382 [16032/60000]\n",
      "loss: 0.865290 [19232/60000]\n",
      "loss: 0.756024 [22432/60000]\n",
      "loss: 0.419715 [25632/60000]\n",
      "loss: 0.478304 [28832/60000]\n",
      "loss: 0.542875 [32032/60000]\n",
      "loss: 0.273117 [35232/60000]\n",
      "loss: 0.814073 [38432/60000]\n",
      "loss: 0.685040 [41632/60000]\n",
      "loss: 0.626642 [44832/60000]\n",
      "loss: 0.709482 [48032/60000]\n",
      "loss: 0.320768 [51232/60000]\n",
      "loss: 0.341937 [54432/60000]\n",
      "loss: 0.576670 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.415321 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.364633 [   32/60000]\n",
      "loss: 0.228416 [ 3232/60000]\n",
      "loss: 0.372986 [ 6432/60000]\n",
      "loss: 0.426844 [ 9632/60000]\n",
      "loss: 0.203570 [12832/60000]\n",
      "loss: 0.520586 [16032/60000]\n",
      "loss: 0.301315 [19232/60000]\n",
      "loss: 0.282581 [22432/60000]\n",
      "loss: 0.353602 [25632/60000]\n",
      "loss: 0.370581 [28832/60000]\n",
      "loss: 0.311920 [32032/60000]\n",
      "loss: 0.466609 [35232/60000]\n",
      "loss: 0.339239 [38432/60000]\n",
      "loss: 0.452785 [41632/60000]\n",
      "loss: 0.213049 [44832/60000]\n",
      "loss: 0.722849 [48032/60000]\n",
      "loss: 0.127884 [51232/60000]\n",
      "loss: 0.284025 [54432/60000]\n",
      "loss: 0.386386 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.330347 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.416076 [   32/60000]\n",
      "loss: 0.151550 [ 3232/60000]\n",
      "loss: 0.239018 [ 6432/60000]\n",
      "loss: 0.213192 [ 9632/60000]\n",
      "loss: 0.582086 [12832/60000]\n",
      "loss: 0.201087 [16032/60000]\n",
      "loss: 0.257045 [19232/60000]\n",
      "loss: 0.268855 [22432/60000]\n",
      "loss: 0.452080 [25632/60000]\n",
      "loss: 0.337481 [28832/60000]\n",
      "loss: 0.108600 [32032/60000]\n",
      "loss: 0.785653 [35232/60000]\n",
      "loss: 0.321530 [38432/60000]\n",
      "loss: 0.435169 [41632/60000]\n",
      "loss: 0.120267 [44832/60000]\n",
      "loss: 0.267554 [48032/60000]\n",
      "loss: 0.633723 [51232/60000]\n",
      "loss: 0.246795 [54432/60000]\n",
      "loss: 0.328560 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.292808 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.279241 [   32/60000]\n",
      "loss: 0.407041 [ 3232/60000]\n",
      "loss: 0.496702 [ 6432/60000]\n",
      "loss: 0.476219 [ 9632/60000]\n",
      "loss: 0.405035 [12832/60000]\n",
      "loss: 0.309197 [16032/60000]\n",
      "loss: 0.149126 [19232/60000]\n",
      "loss: 0.338314 [22432/60000]\n",
      "loss: 0.250150 [25632/60000]\n",
      "loss: 0.192369 [28832/60000]\n",
      "loss: 0.591450 [32032/60000]\n",
      "loss: 0.492348 [35232/60000]\n",
      "loss: 0.457445 [38432/60000]\n",
      "loss: 0.222816 [41632/60000]\n",
      "loss: 0.241957 [44832/60000]\n",
      "loss: 0.124549 [48032/60000]\n",
      "loss: 0.098023 [51232/60000]\n",
      "loss: 0.023354 [54432/60000]\n",
      "loss: 0.231018 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.263649 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.234109 [   32/60000]\n",
      "loss: 0.393789 [ 3232/60000]\n",
      "loss: 0.093111 [ 6432/60000]\n",
      "loss: 0.382193 [ 9632/60000]\n",
      "loss: 0.338471 [12832/60000]\n",
      "loss: 0.272598 [16032/60000]\n",
      "loss: 0.125255 [19232/60000]\n",
      "loss: 0.505984 [22432/60000]\n",
      "loss: 0.329378 [25632/60000]\n",
      "loss: 0.336211 [28832/60000]\n",
      "loss: 0.242816 [32032/60000]\n",
      "loss: 0.253608 [35232/60000]\n",
      "loss: 0.227506 [38432/60000]\n",
      "loss: 0.161595 [41632/60000]\n",
      "loss: 0.254505 [44832/60000]\n",
      "loss: 0.105085 [48032/60000]\n",
      "loss: 0.376054 [51232/60000]\n",
      "loss: 0.352303 [54432/60000]\n",
      "loss: 0.173673 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.243177 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_data_loader, model, loss_fn, optimizer)\n",
    "    test(train_data_loader, model, loss_fn)\n",
    "print('Done!')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.93235\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9331\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
    "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Загрузите файл `hw07_data_dict.npy` (ссылка есть на странице с заданием) и запустите код ниже для генерации посылки. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/23s_dd_ml/homeworks/hw07_mnist_classification/hw07_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_hw07.npy`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import os\n",
    "\n",
    "assert os.path.exists('hw07_data_dict.npy'), 'Please, download `hw07_data_dict.npy` and place it in the working directory'\n",
    "\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "    \n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "    \n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    return predicted_labels\n",
    "\n",
    "loaded_data_dict = np.load('hw07_data_dict.npy', allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])).numpy(),\n",
    "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test'])).numpy()\n",
    "}\n",
    "\n",
    "np.save('submission_dict_hw07.npy', submission_dict, allow_pickle=True)\n",
    "print('File saved to `submission_dict_hw07.npy`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
